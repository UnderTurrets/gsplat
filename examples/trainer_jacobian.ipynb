{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import imageio\n",
    "import nerfview\n",
    "import numpy as np\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "import tyro\n",
    "import viser\n",
    "from gsplat.distributed import cli\n",
    "from gsplat.strategy import DefaultStrategy, MCMCStrategy\n",
    "from torch import Tensor\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchmetrics.image import PeakSignalNoiseRatio, StructuralSimilarityIndexMeasure\n",
    "from torchmetrics.image.lpip import LearnedPerceptualImagePatchSimilarity\n",
    "from typing_extensions import assert_never\n",
    "\n",
    "from datasets.colmap import Dataset, Parser\n",
    "from datasets.traj import generate_interpolated_path\n",
    "from utils import AppearanceOptModule, CameraOptModule, knn, rgb_to_sh, set_random_seed\n",
    "\n",
    "from gsplat.rendering import rasterization,_rasterization, rasterization_jacobian\n",
    "from gsplat.strategy import DefaultStrategy"
   ],
   "id": "6890103ec6412f12"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# config hpyerparameters",
   "id": "3d68830ab34b347c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    # Disable viewer\n",
    "    disable_viewer: bool = False\n",
    "    # Path to the .pt file. If provide, it will skip training and render a video\n",
    "    ckpt: Optional[str] = None\n",
    "\n",
    "    # Path to dataset\n",
    "    data_dir: str = rf\"{os.path.dirname(__file__)}/datasets/lego_2\"\n",
    "    # Downsample factor for the dataset\n",
    "    data_factor: int = 1  # 4\n",
    "    # Directory to save results\n",
    "    result_dir: str = rf\"{os.path.dirname(__file__)}/results/lego_2\"\n",
    "    # Every N images there is a test image\n",
    "    test_every: int = 8\n",
    "    # Random crop size for training  (experimental)\n",
    "    patch_size: Optional[int] = None\n",
    "    # A global scaler that applies to the scene size related parameters\n",
    "    global_scale: float = 1.0\n",
    "\n",
    "    # Port for the viewer server\n",
    "    port: int = 8080\n",
    "\n",
    "    # Batch size for training. Learning rates are scaled automatically\n",
    "    batch_size: int = 1\n",
    "    # A global factor to scale the number of training steps\n",
    "    steps_scaler: float = 1.0\n",
    "\n",
    "    # Number of training steps\n",
    "    max_steps: int = 30_000\n",
    "    # Steps to evaluate the model\n",
    "    eval_steps: List[int] = field(default_factory=lambda: [7_000, 30_000])\n",
    "    # Steps to save the model\n",
    "    save_steps: List[int] = field(default_factory=lambda: [7_000, 30_000])\n",
    "\n",
    "    # Initialization strategy\n",
    "    init_type: str = \"sfm\"\n",
    "    # Initial number of GSs. Ignored if using sfm\n",
    "    init_num_pts: int = 100_000\n",
    "    # Initial extent of GSs as a multiple of the camera extent. Ignored if using sfm\n",
    "    init_extent: float = 3.0\n",
    "    # Degree of spherical harmonics\n",
    "    sh_degree: int = 3\n",
    "    # Turn on another SH degree every this steps\n",
    "    sh_degree_interval: int = 1000\n",
    "    # Initial opacity of GS\n",
    "    init_opa: float = 0.1\n",
    "    # Initial scale of GS\n",
    "    init_scale: float = 1.0\n",
    "    # Weight for SSIM loss\n",
    "    ssim_lambda: float = 0.2\n",
    "\n",
    "    # Near plane clipping distance\n",
    "    near_plane: float = 0.01\n",
    "    # Far plane clipping distance\n",
    "    far_plane: float = 1e10\n",
    "\n",
    "    # Strategy for GS densification\n",
    "    strategy: Union[DefaultStrategy, MCMCStrategy] = field(\n",
    "        default_factory=DefaultStrategy\n",
    "    )\n",
    "    # Use packed mode for rasterization, this leads to less memory usage but slightly slower.\n",
    "    packed: bool = False\n",
    "    # Use sparse gradients for optimization. (experimental)\n",
    "    sparse_grad: bool = False\n",
    "    # Anti-aliasing in rasterization. Might slightly hurt quantitative metrics.\n",
    "    antialiased: bool = False\n",
    "\n",
    "    # Use random background for training to discourage transparency\n",
    "    random_bkgd: bool = False\n",
    "\n",
    "    # Enable camera optimization.\n",
    "    pose_opt: bool = False\n",
    "    # Learning rate for camera optimization\n",
    "    pose_opt_lr: float = 1e-5\n",
    "    # Regularization for camera optimization as weight decay\n",
    "    pose_opt_reg: float = 1e-6\n",
    "    # Add noise to camera extrinsics. This is only to test the camera pose optimization.\n",
    "    pose_noise: float = 0.0\n",
    "\n",
    "    # Enable appearance optimization. (experimental)\n",
    "    app_opt: bool = False\n",
    "    # Appearance embedding dimension\n",
    "    app_embed_dim: int = 16\n",
    "    # Learning rate for appearance optimization\n",
    "    app_opt_lr: float = 1e-3\n",
    "    # Regularization for appearance optimization as weight decay\n",
    "    app_opt_reg: float = 1e-6\n",
    "\n",
    "    # Enable depth loss. (experimental)\n",
    "    depth_loss: bool = False\n",
    "    # Weight for depth loss\n",
    "    depth_lambda: float = 1e-2\n",
    "\n",
    "    # Dump information to tensorboard every this steps\n",
    "    tb_every: int = 100\n",
    "    # Save training images to tensorboard\n",
    "    tb_save_image: bool = False\n",
    "\n",
    "    def adjust_steps(self, factor: float):\n",
    "        self.eval_steps = [int(i * factor) for i in self.eval_steps]\n",
    "        self.save_steps = [int(i * factor) for i in self.save_steps]\n",
    "        self.max_steps = int(self.max_steps * factor)\n",
    "        self.sh_degree_interval = int(self.sh_degree_interval * factor)\n",
    "\n",
    "        strategy = self.strategy\n",
    "        if isinstance(strategy, DefaultStrategy):\n",
    "            strategy.refine_start_iter = int(strategy.refine_start_iter * factor)\n",
    "            strategy.refine_stop_iter = int(strategy.refine_stop_iter * factor)\n",
    "            strategy.reset_every = int(strategy.reset_every * factor)\n",
    "            strategy.refine_every = int(strategy.refine_every * factor)\n",
    "        elif isinstance(strategy, MCMCStrategy):\n",
    "            strategy.refine_start_iter = int(strategy.refine_start_iter * factor)\n",
    "            strategy.refine_stop_iter = int(strategy.refine_stop_iter * factor)\n",
    "            strategy.refine_every = int(strategy.refine_every * factor)\n",
    "        else:\n",
    "            assert_never(strategy)"
   ],
   "id": "2e9efad2f37df6a0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# prepare data and optimizers",
   "id": "763f8669b8568a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_splats_with_optimizers(\n",
    "    parser: Parser,\n",
    "    init_type: str = \"sfm\",\n",
    "    init_num_pts: int = 100_000,\n",
    "    init_extent: float = 3.0,\n",
    "    init_opacity: float = 0.1,\n",
    "    init_scale: float = 1.0,\n",
    "    scene_scale: float = 1.0,\n",
    "    sh_degree: int = 3,\n",
    "    sparse_grad: bool = False,\n",
    "    batch_size: int = 1,\n",
    "    feature_dim: Optional[int] = None,\n",
    "    device: str = \"cuda\",\n",
    "    world_rank: int = 0,\n",
    "    world_size: int = 1,\n",
    ") -> Tuple[torch.nn.ParameterDict, Dict[str, torch.optim.Optimizer]]:\n",
    "    if init_type == \"sfm\":\n",
    "        points = torch.from_numpy(parser.points).float()\n",
    "        rgbs = torch.from_numpy(parser.points_rgb / 255.0).float()\n",
    "    elif init_type == \"random\":\n",
    "        points = init_extent * scene_scale * (torch.rand((init_num_pts, 3)) * 2 - 1)\n",
    "        rgbs = torch.rand((init_num_pts, 3))\n",
    "    else:\n",
    "        raise ValueError(\"Please specify a correct init_type: sfm or random\")\n",
    "\n",
    "    # Initialize the GS size to be the average dist of the 3 nearest neighbors\n",
    "    # 通过scikit库的knn近邻算法选出距离自己最近的三个点并平方，在最后一个维度取平均 [N,3]->[N,]\n",
    "    # 均方根距离平均\n",
    "    dist2_avg = (knn(points, 4)[:, 1:] ** 2).mean(dim=-1)  # [N,]\n",
    "    dist_avg = torch.sqrt(dist2_avg)\n",
    "    # 基于近邻距离取对数值初始化，并复制成3个相同的值，后续再exp运算，但优化时是根据对数空间的参数进行优化\n",
    "    scales = torch.log(dist_avg * init_scale).unsqueeze(-1).repeat(1, 3)  # [N, 3]\n",
    "\n",
    "    # Distribute the GSs to different ranks (also works for single rank)\n",
    "    points = points[world_rank::world_size]\n",
    "    rgbs = rgbs[world_rank::world_size]\n",
    "    scales = scales[world_rank::world_size]\n",
    "\n",
    "    N = points.shape[0]\n",
    "    # 生成随机四元数\n",
    "    quats = torch.rand((N, 4))  # [N, 4]\n",
    "\n",
    "    # 用logit函数初始化不透明度，后续再sigmoid运算，但优化时是根据对数空间的参数进行优化\n",
    "    opacities = torch.logit(torch.full((N,), init_opacity))  # [N,]\n",
    "\n",
    "    params = [\n",
    "        # name, value, lr\n",
    "        (\"means\", torch.nn.Parameter(points), 1.6e-4 * scene_scale),\n",
    "        (\"scales\", torch.nn.Parameter(scales), 5e-3),\n",
    "        (\"quats\", torch.nn.Parameter(quats), 1e-3),\n",
    "        (\"opacities\", torch.nn.Parameter(opacities), 5e-2),\n",
    "    ]\n",
    "\n",
    "    if feature_dim is None:\n",
    "        # color is SH coefficients.\n",
    "        colors = torch.zeros((N, (sh_degree + 1) ** 2, 3))  # [N, K, 3]\n",
    "        colors[:, 0, :] = rgb_to_sh(rgbs)\n",
    "        params.append((\"sh0\", torch.nn.Parameter(colors[:, :1, :]), 2.5e-3))\n",
    "        params.append((\"shN\", torch.nn.Parameter(colors[:, 1:, :]), 2.5e-3 / 20))\n",
    "    else:\n",
    "        # 使用特征向量来进行外观和视角相关的着色。\n",
    "        # features will be used for appearance and view-dependent shading\n",
    "        features = torch.rand(N, feature_dim)  # [N, feature_dim]\n",
    "        params.append((\"features\", torch.nn.Parameter(features), 2.5e-3))\n",
    "        colors = torch.logit(rgbs)  # [N, 3]\n",
    "        params.append((\"colors\", torch.nn.Parameter(colors), 2.5e-3))\n",
    "\n",
    "    splats = torch.nn.ParameterDict({n: v for n, v, _ in params}).to(device)\n",
    "    # Scale learning rate based on batch size, reference:\n",
    "    # https://www.cs.princeton.edu/~smalladi/blog/2024/01/22/SDEs-ScalingRules/\n",
    "    # Note that this would not make the training exactly equivalent, see\n",
    "    # https://arxiv.org/pdf/2402.18824v1\n",
    "    BS = batch_size * world_size\n",
    "    optimizers = {\n",
    "        name: (torch.optim.SparseAdam if sparse_grad else torch.optim.Adam)(\n",
    "            [{\"params\": splats[name], \"lr\": lr * math.sqrt(BS), \"name\": name}],\n",
    "            eps=1e-15 / math.sqrt(BS),\n",
    "            # TODO: check betas logic when BS is larger than 10 betas[0] will be zero.\n",
    "            betas=(1 - BS * (1 - 0.9), 1 - BS * (1 - 0.999)),\n",
    "        )\n",
    "        for name, _, lr in params\n",
    "    }\n",
    "    return splats, optimizers"
   ],
   "id": "c4bf154e71ecbcea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Runner",
   "id": "5daf83c151b7183d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Runner:\n",
    "    \"\"\"Engine for training and testing.\"\"\"\n",
    "    def __init__(\n",
    "        self, local_rank: int, world_rank, world_size: int, cfg: Config\n",
    "    ) -> None:\n",
    "        set_random_seed(42 + local_rank)\n",
    "\n",
    "        self.cfg = cfg\n",
    "        self.world_rank = world_rank\n",
    "        self.local_rank = local_rank\n",
    "        self.world_size = world_size\n",
    "        self.device = f\"cuda:{local_rank}\"\n",
    "\n",
    "        # Where to dump results.\n",
    "        os.makedirs(cfg.result_dir, exist_ok=True)\n",
    "\n",
    "        # Setup output directories.\n",
    "        self.ckpt_dir = f\"{cfg.result_dir}/ckpts\"\n",
    "        os.makedirs(self.ckpt_dir, exist_ok=True)\n",
    "        self.stats_dir = f\"{cfg.result_dir}/stats\"\n",
    "        os.makedirs(self.stats_dir, exist_ok=True)\n",
    "        self.render_dir = f\"{cfg.result_dir}/renders\"\n",
    "        os.makedirs(self.render_dir, exist_ok=True)\n",
    "\n",
    "        # Tensorboard\n",
    "        self.writer = SummaryWriter(log_dir=f\"{cfg.result_dir}/tb\")\n",
    "\n",
    "        # Load data: Training data should contain initial points and colors.\n",
    "        self.parser = Parser(\n",
    "            data_dir=cfg.data_dir,\n",
    "            factor=cfg.data_factor,\n",
    "            normalize=True,\n",
    "            test_every=cfg.test_every,\n",
    "        )\n",
    "        self.trainset = Dataset(\n",
    "            self.parser,\n",
    "            split=\"train\",\n",
    "            patch_size=cfg.patch_size,\n",
    "            load_depths=cfg.depth_loss,\n",
    "        )\n",
    "        self.valset = Dataset(self.parser, split=\"val\")\n",
    "        self.scene_scale = self.parser.scene_scale * 1.1 * cfg.global_scale\n",
    "        print(\"Scene scale:\", self.scene_scale)\n",
    "\n",
    "        # Model\n",
    "        feature_dim = 32 if cfg.app_opt else None\n",
    "        self.splats, self.optimizers = create_splats_with_optimizers(\n",
    "            self.parser,\n",
    "            init_type=cfg.init_type,\n",
    "            init_num_pts=cfg.init_num_pts,\n",
    "            init_extent=cfg.init_extent,\n",
    "            init_opacity=cfg.init_opa,\n",
    "            init_scale=cfg.init_scale,\n",
    "            scene_scale=self.scene_scale,\n",
    "            sh_degree=cfg.sh_degree,\n",
    "            sparse_grad=cfg.sparse_grad,\n",
    "            batch_size=cfg.batch_size,\n",
    "            feature_dim=feature_dim,\n",
    "            device=self.device,\n",
    "            world_rank=world_rank,\n",
    "            world_size=world_size,\n",
    "        )\n",
    "        print(\"Model initialized. Number of GS:\", len(self.splats[\"means\"]))\n",
    "\n",
    "        # Densification Strategy\n",
    "        self.cfg.strategy.check_sanity(self.splats, self.optimizers)\n",
    "\n",
    "        if isinstance(self.cfg.strategy, DefaultStrategy):\n",
    "            self.strategy_state = self.cfg.strategy.initialize_state(\n",
    "                scene_scale=self.scene_scale\n",
    "            )\n",
    "        elif isinstance(self.cfg.strategy, MCMCStrategy):\n",
    "            self.strategy_state = self.cfg.strategy.initialize_state()\n",
    "        else:\n",
    "            assert_never(self.cfg.strategy)\n",
    "\n",
    "        self.pose_optimizers = []\n",
    "        if cfg.pose_opt:\n",
    "            self.pose_adjust = CameraOptModule(len(self.trainset)).to(self.device)\n",
    "            self.pose_adjust.zero_init()\n",
    "            self.pose_optimizers = [\n",
    "                torch.optim.Adam(\n",
    "                    self.pose_adjust.parameters(),\n",
    "                    lr=cfg.pose_opt_lr * math.sqrt(cfg.batch_size),\n",
    "                    weight_decay=cfg.pose_opt_reg,\n",
    "                )\n",
    "            ]\n",
    "            if world_size > 1:\n",
    "                self.pose_adjust = DDP(self.pose_adjust)\n",
    "\n",
    "        if cfg.pose_noise > 0.0:\n",
    "            self.pose_perturb = CameraOptModule(len(self.trainset)).to(self.device)\n",
    "            self.pose_perturb.random_init(cfg.pose_noise)\n",
    "            if world_size > 1:\n",
    "                self.pose_perturb = DDP(self.pose_perturb)\n",
    "\n",
    "        self.app_optimizers = []\n",
    "        if cfg.app_opt:\n",
    "            assert feature_dim is not None\n",
    "            self.app_module = AppearanceOptModule(\n",
    "                len(self.trainset), feature_dim, cfg.app_embed_dim, cfg.sh_degree\n",
    "            ).to(self.device)\n",
    "            # initialize the last layer to be zero so that the initial output is zero.\n",
    "            torch.nn.init.zeros_(self.app_module.color_head[-1].weight)\n",
    "            torch.nn.init.zeros_(self.app_module.color_head[-1].bias)\n",
    "            self.app_optimizers = [\n",
    "                torch.optim.Adam(\n",
    "                    self.app_module.embeds.parameters(),\n",
    "                    lr=cfg.app_opt_lr * math.sqrt(cfg.batch_size) * 10.0,\n",
    "                    weight_decay=cfg.app_opt_reg,\n",
    "                ),\n",
    "                torch.optim.Adam(\n",
    "                    self.app_module.color_head.parameters(),\n",
    "                    lr=cfg.app_opt_lr * math.sqrt(cfg.batch_size),\n",
    "                ),\n",
    "            ]\n",
    "            if world_size > 1:\n",
    "                self.app_module = DDP(self.app_module)\n",
    "\n",
    "        # Losses & Metrics.\n",
    "        self.ssim = StructuralSimilarityIndexMeasure(data_range=1.0).to(self.device)\n",
    "        self.psnr = PeakSignalNoiseRatio(data_range=1.0).to(self.device)\n",
    "        self.lpips = LearnedPerceptualImagePatchSimilarity(normalize=True).to(\n",
    "            self.device\n",
    "        )\n",
    "\n",
    "        # Viewer\n",
    "        if not self.cfg.disable_viewer:\n",
    "            self.server = viser.ViserServer(port=cfg.port, verbose=False)\n",
    "            self.viewer = nerfview.Viewer(\n",
    "                server=self.server,\n",
    "                render_fn=self._viewer_render_fn,\n",
    "                mode=\"training\",\n",
    "            )\n",
    "\n",
    "    def rasterize_splats(\n",
    "        self,\n",
    "        camtoworlds: Tensor,\n",
    "        Ks: Tensor,\n",
    "        width: int,\n",
    "        height: int,\n",
    "        get_jacobian: bool = False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        means = self.splats[\"means\"]  # [N, 3]\n",
    "        # quats = F.normalize(self.splats[\"quats\"], dim=-1)  # [N, 4]\n",
    "        # rasterization does normalization internally\n",
    "        quats = self.splats[\"quats\"]  # [N, 4]\n",
    "        scales = torch.exp(self.splats[\"scales\"])  # [N, 3]\n",
    "        opacities = torch.sigmoid(self.splats[\"opacities\"])  # [N,]\n",
    "\n",
    "        image_ids = kwargs.pop(\"image_ids\", None)\n",
    "        target_colors = kwargs.pop(\"target_colors\", Tensor)\n",
    "        if self.cfg.app_opt:\n",
    "            colors = self.app_module(\n",
    "                features=self.splats[\"features\"],\n",
    "                embed_ids=image_ids,\n",
    "                dirs=means[None, :, :] - camtoworlds[:, None, :3, 3],\n",
    "                sh_degree=kwargs.pop(\"sh_degree\", self.cfg.sh_degree),\n",
    "            )\n",
    "            colors = colors + self.splats[\"colors\"]\n",
    "            colors = torch.sigmoid(colors)\n",
    "\n",
    "        # 把球谐函数的参数叠起来\n",
    "        else:\n",
    "            colors = torch.cat([self.splats[\"sh0\"], self.splats[\"shN\"]], 1)  # [N, K, 3]\n",
    "\n",
    "        rasterize_mode = \"antialiased\" if self.cfg.antialiased else \"classic\"\n",
    "        if get_jacobian:\n",
    "            ## jacobian\n",
    "            kwargs.pop(\"render_mode\", str)\n",
    "            render_colors, render_alphas, info, jacobian = rasterization_jacobian(\n",
    "                means=means,\n",
    "                quats=quats,\n",
    "                scales=scales,\n",
    "                opacities=opacities,\n",
    "                coeffs=colors,\n",
    "                viewmats=torch.linalg.inv(camtoworlds),  # [C, 4, 4]\n",
    "                Ks=Ks,  # [C, 3, 3]\n",
    "                target_colors=target_colors,\n",
    "                rasterize_mode=rasterize_mode,\n",
    "                width=width,\n",
    "                height=height,\n",
    "                distributed=self.world_size > 1,\n",
    "                **kwargs,\n",
    "            )\n",
    "            return render_colors, render_alphas, info, jacobian\n",
    "        else:\n",
    "            ## CUDA complementation\n",
    "            render_colors, render_alphas, info = rasterization(\n",
    "                means=means,\n",
    "                quats=quats,\n",
    "                scales=scales,\n",
    "                opacities=opacities,\n",
    "                colors=colors,\n",
    "                viewmats=torch.linalg.inv(camtoworlds),  # [C, 4, 4]\n",
    "                Ks=Ks,  # [C, 3, 3]\n",
    "                width=width,\n",
    "                height=height,\n",
    "                packed=self.cfg.packed,\n",
    "                absgrad=(\n",
    "                    self.cfg.strategy.absgrad\n",
    "                    if isinstance(self.cfg.strategy, DefaultStrategy)\n",
    "                    else False\n",
    "                ),\n",
    "                sparse_grad=self.cfg.sparse_grad,\n",
    "                rasterize_mode=rasterize_mode,\n",
    "                distributed=self.world_size > 1,\n",
    "                **kwargs,\n",
    "            )\n",
    "            ## torch complementation\n",
    "            # render_colors, render_alphas, info = _rasterization(\n",
    "            #     means=means,\n",
    "            #     quats=quats,\n",
    "            #     scales=scales,\n",
    "            #     opacities=opacities,\n",
    "            #     colors=colors,\n",
    "            #     viewmats=torch.linalg.inv(camtoworlds),  # [C, 4, 4]\n",
    "            #     Ks=Ks,  # [C, 3, 3]\n",
    "            #     width=width,\n",
    "            #     height=height,\n",
    "            #     rasterize_mode=rasterize_mode,\n",
    "            #     **kwargs,\n",
    "            # )\n",
    "            return render_colors, render_alphas, info\n",
    "\n",
    "    def train(self):\n",
    "        cfg = self.cfg\n",
    "        device = self.device\n",
    "        world_rank = self.world_rank\n",
    "        world_size = self.world_size\n",
    "\n",
    "        # Dump cfg.\n",
    "        if world_rank == 0:\n",
    "            with open(f\"{cfg.result_dir}/cfg.yml\", \"w\") as f:\n",
    "                yaml.dump(vars(cfg), f)\n",
    "\n",
    "        max_steps = cfg.max_steps\n",
    "        init_step = 0\n",
    "\n",
    "        schedulers = [\n",
    "            # means has a learning rate schedule, that end at 0.01 of the initial value\n",
    "            torch.optim.lr_scheduler.ExponentialLR(\n",
    "                self.optimizers[\"means\"], gamma=0.01 ** (1.0 / max_steps)\n",
    "            ),\n",
    "        ]\n",
    "        if cfg.pose_opt:\n",
    "            # pose optimization has a learning rate schedule\n",
    "            schedulers.append(\n",
    "                torch.optim.lr_scheduler.ExponentialLR(\n",
    "                    self.pose_optimizers[0], gamma=0.01 ** (1.0 / max_steps)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(\n",
    "            self.trainset,\n",
    "            batch_size=cfg.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=4,\n",
    "            persistent_workers=True,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "        trainloader_iter = iter(trainloader)\n",
    "\n",
    "        from gsplat.LMoptimizer import LevenbergMarquardt\n",
    "        params = [self.splats[\"means\"],\n",
    "                  self.splats[\"scales\"],\n",
    "                  self.splats[\"quats\"],\n",
    "                  self.splats[\"opacities\"],\n",
    "                  self.splats[\"sh0\"],\n",
    "                  self.splats[\"shN\"]\n",
    "                  ]\n",
    "        LMoptimizer = LevenbergMarquardt(params,)\n",
    "\n",
    "        # Training loop.\n",
    "        # prof = torch.profiler.profile(\n",
    "        #     schedule=torch.profiler.schedule(wait=1, warmup=1, active=50, repeat=1),\n",
    "        #     on_trace_ready=torch.profiler.tensorboard_trace_handler(f\"{self.cfg.result_dir}/tb\"),\n",
    "        #     profile_memory=True,\n",
    "        #     record_shapes=True,\n",
    "        #     with_stack=True)\n",
    "        # prof.start()\n",
    "        global_tic = time.time()\n",
    "        pbar = tqdm.tqdm(range(init_step, max_steps))\n",
    "        for step in pbar:\n",
    "            # prof.step()\n",
    "            if not cfg.disable_viewer:\n",
    "                while self.viewer.state.status == \"paused\":\n",
    "                    time.sleep(0.01)\n",
    "                self.viewer.lock.acquire()\n",
    "                tic = time.time()\n",
    "\n",
    "            try:\n",
    "                data = next(trainloader_iter)\n",
    "            except StopIteration:\n",
    "                trainloader_iter = iter(trainloader)\n",
    "                data = next(trainloader_iter)\n",
    "\n",
    "            camtoworlds = camtoworlds_gt = data[\"camtoworld\"].to(device)  # [1, 4, 4]\n",
    "            Ks = data[\"K\"].to(device)  # [1, 3, 3]\n",
    "            pixels = data[\"image\"].to(device) / 255.0  # [1, H, W, 3]\n",
    "            num_train_rays_per_step = (\n",
    "                pixels.shape[0] * pixels.shape[1] * pixels.shape[2]\n",
    "            )\n",
    "            image_ids = data[\"image_id\"].to(device)\n",
    "            if cfg.depth_loss:\n",
    "                points = data[\"points\"].to(device)  # [1, M, 2]\n",
    "                depths_gt = data[\"depths\"].to(device)  # [1, M]\n",
    "\n",
    "            height, width = pixels.shape[1:3]\n",
    "\n",
    "            if cfg.pose_noise:\n",
    "                camtoworlds = self.pose_perturb(camtoworlds, image_ids)\n",
    "\n",
    "            if cfg.pose_opt:\n",
    "                camtoworlds = self.pose_adjust(camtoworlds, image_ids)\n",
    "\n",
    "            # sh schedule\n",
    "            sh_degree_to_use = min(step // cfg.sh_degree_interval, cfg.sh_degree)\n",
    "\n",
    "            # forward\n",
    "            renders, alphas, info, jacobians = self.rasterize_splats(\n",
    "                camtoworlds=camtoworlds,\n",
    "                Ks=Ks,\n",
    "                width=width,\n",
    "                height=height,\n",
    "                get_jacobian=True,\n",
    "                # kargs\n",
    "                sh_degree=sh_degree_to_use,\n",
    "                near_plane=cfg.near_plane,\n",
    "                far_plane=cfg.far_plane,\n",
    "                image_ids=image_ids,\n",
    "                render_mode=\"RGB+ED\" if cfg.depth_loss else \"RGB\",\n",
    "                target_colors = pixels,\n",
    "            )\n",
    "            jacobians = torch.unbind(jacobians, dim=0)\n",
    "            if renders.shape[-1] == 4:\n",
    "                colors, depths = renders[..., 0:3], renders[..., 3:4]\n",
    "            else:\n",
    "                colors, depths = renders, None\n",
    "\n",
    "            if cfg.random_bkgd:\n",
    "                bkgd = torch.rand(1, 3, device=device)\n",
    "                colors = colors + bkgd * (1.0 - alphas)\n",
    "\n",
    "            self.cfg.strategy.step_pre_backward(\n",
    "                params=self.splats,\n",
    "                optimizers=self.optimizers,\n",
    "                state=self.strategy_state,\n",
    "                step=step,\n",
    "                info=info,\n",
    "            )\n",
    "\n",
    "            residual = (colors - pixels).sum(dim=-1, keepdim=True)\n",
    "            residual = residual.flatten()\n",
    "\n",
    "            # loss\n",
    "            l1loss = F.l1_loss(colors, pixels)\n",
    "            ssimloss = 1.0 - self.ssim(\n",
    "                # (1,H,W,Channel)->(1,Channel,H,W)\n",
    "                pixels.permute(0, 3, 1, 2), colors.permute(0, 3, 1, 2)\n",
    "            )\n",
    "            loss = l1loss * (1.0 - cfg.ssim_lambda) + ssimloss * cfg.ssim_lambda\n",
    "            loss.backward()\n",
    "\n",
    "            desc = f\"loss={loss.item():.3f}| \" f\"sh degree={sh_degree_to_use}| \"\n",
    "            if cfg.pose_opt and cfg.pose_noise:\n",
    "                # monitor the pose error if we inject noise\n",
    "                pose_err = F.l1_loss(camtoworlds_gt, camtoworlds)\n",
    "                desc += f\"pose err={pose_err.item():.6f}| \"\n",
    "            pbar.set_description(desc)\n",
    "\n",
    "            desc = f\"loss={loss.item():.3f}| \" f\"sh degree={sh_degree_to_use}| \"\n",
    "            if cfg.pose_opt and cfg.pose_noise:\n",
    "                # monitor the pose error if we inject noise\n",
    "                pose_err = F.l1_loss(camtoworlds_gt, camtoworlds)\n",
    "                desc += f\"pose err={pose_err.item():.6f}| \"\n",
    "            pbar.set_description(desc)\n",
    "\n",
    "            if world_rank == 0 and cfg.tb_every > 0 and step % cfg.tb_every == 0:\n",
    "                mem = torch.cuda.max_memory_allocated() / 1024**3\n",
    "                self.writer.add_scalar(\"train/loss\", loss.item(), step)\n",
    "                self.writer.add_scalar(\"train/num_GS\", len(self.splats[\"means\"]), step)\n",
    "                self.writer.add_scalar(\"train/mem\", mem, step)\n",
    "                if cfg.tb_save_image:\n",
    "                    canvas = torch.cat([pixels, colors], dim=2).detach().cpu().numpy()\n",
    "                    canvas = canvas.reshape(-1, *canvas.shape[2:])\n",
    "                    self.writer.add_image(\"train/render\", canvas, step)\n",
    "                self.writer.flush()\n",
    "\n",
    "            # save checkpoint before updating the model\n",
    "            if step in [i - 1 for i in cfg.save_steps] or step == max_steps - 1:\n",
    "                mem = torch.cuda.max_memory_allocated() / 1024**3\n",
    "                stats = {\n",
    "                    \"mem\": mem,\n",
    "                    \"ellipse_time\": time.time() - global_tic,\n",
    "                    \"num_GS\": len(self.splats[\"means\"]),\n",
    "                }\n",
    "                print(\"Step: \", step, stats)\n",
    "                with open(\n",
    "                    f\"{self.stats_dir}/train_step{step:04d}_rank{self.world_rank}.json\",\n",
    "                    \"w\",\n",
    "                ) as f:\n",
    "                    json.dump(stats, f)\n",
    "                data = {\"step\": step, \"splats\": self.splats.state_dict()}\n",
    "                if cfg.pose_opt:\n",
    "                    if world_size > 1:\n",
    "                        data[\"pose_adjust\"] = self.pose_adjust.module.state_dict()\n",
    "                    else:\n",
    "                        data[\"pose_adjust\"] = self.pose_adjust.state_dict()\n",
    "                if cfg.app_opt:\n",
    "                    if world_size > 1:\n",
    "                        data[\"app_module\"] = self.app_module.module.state_dict()\n",
    "                    else:\n",
    "                        data[\"app_module\"] = self.app_module.state_dict()\n",
    "                torch.save(\n",
    "                    data, f\"{self.ckpt_dir}/ckpt_{step}_rank{self.world_rank}.pt\"\n",
    "                )\n",
    "\n",
    "            if isinstance(self.cfg.strategy, DefaultStrategy):\n",
    "                self.cfg.strategy.step_post_backward(\n",
    "                    params=self.splats,\n",
    "                    optimizers=self.optimizers,\n",
    "                    state=self.strategy_state,\n",
    "                    step=step,\n",
    "                    info=info,\n",
    "                    packed=cfg.packed,\n",
    "                )\n",
    "            elif isinstance(self.cfg.strategy, MCMCStrategy):\n",
    "                self.cfg.strategy.step_post_backward(\n",
    "                    params=self.splats,\n",
    "                    optimizers=self.optimizers,\n",
    "                    state=self.strategy_state,\n",
    "                    step=step,\n",
    "                    info=info,\n",
    "                    lr=schedulers[0].get_last_lr()[0],\n",
    "                )\n",
    "            else:\n",
    "                assert_never(self.cfg.strategy)\n",
    "\n",
    "            # optimize\n",
    "            LMoptimizer.step(Jacobians=jacobians,residual=residual)\n",
    "            for optimizer in self.pose_optimizers:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "            for optimizer in self.app_optimizers:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "            for scheduler in schedulers:\n",
    "                scheduler.step()\n",
    "\n",
    "            # eval the full set\n",
    "            if step in [i - 1 for i in cfg.eval_steps]:\n",
    "                self.eval(step)\n",
    "                self.render_traj(step)\n",
    "\n",
    "            if not cfg.disable_viewer:\n",
    "                self.viewer.lock.release()\n",
    "                num_train_steps_per_sec = 1.0 / (time.time() - tic)\n",
    "                num_train_rays_per_sec = (\n",
    "                    num_train_rays_per_step * num_train_steps_per_sec\n",
    "                )\n",
    "                # Update the viewer state.\n",
    "                self.viewer.state.num_train_rays_per_sec = num_train_rays_per_sec\n",
    "                # Update the scene.\n",
    "                self.viewer.update(step, num_train_rays_per_step)\n",
    "        # prof.stop()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def eval(self, step: int):\n",
    "        \"\"\"Entry for evaluation.\"\"\"\n",
    "        print(\"Running evaluation...\")\n",
    "        cfg = self.cfg\n",
    "        device = self.device\n",
    "        world_rank = self.world_rank\n",
    "        world_size = self.world_size\n",
    "\n",
    "        valloader = torch.utils.data.DataLoader(\n",
    "            self.valset, batch_size=1, shuffle=False, num_workers=1\n",
    "        )\n",
    "        ellipse_time = 0\n",
    "        metrics = {\"psnr\": [], \"ssim\": [], \"lpips\": []}\n",
    "        for i, data in enumerate(valloader):\n",
    "            camtoworlds = data[\"camtoworld\"].to(device)\n",
    "            Ks = data[\"K\"].to(device)\n",
    "            pixels = data[\"image\"].to(device) / 255.0\n",
    "            height, width = pixels.shape[1:3]\n",
    "\n",
    "            torch.cuda.synchronize()\n",
    "            tic = time.time()\n",
    "            colors, _, _ = self.rasterize_splats(\n",
    "                camtoworlds=camtoworlds,\n",
    "                Ks=Ks,\n",
    "                width=width,\n",
    "                height=height,\n",
    "                sh_degree=cfg.sh_degree,\n",
    "                near_plane=cfg.near_plane,\n",
    "                far_plane=cfg.far_plane,\n",
    "            )  # [1, H, W, 3]\n",
    "            colors = torch.clamp(colors, 0.0, 1.0)\n",
    "            torch.cuda.synchronize()\n",
    "            ellipse_time += time.time() - tic\n",
    "\n",
    "            if world_rank == 0:\n",
    "                # write images\n",
    "                canvas = torch.cat([pixels, colors], dim=2).squeeze(0).cpu().numpy()\n",
    "                imageio.imwrite(\n",
    "                    f\"{self.render_dir}/val_{i:04d}.png\",\n",
    "                    (canvas * 255).astype(np.uint8),\n",
    "                )\n",
    "\n",
    "                pixels = pixels.permute(0, 3, 1, 2)  # [1, 3, H, W]\n",
    "                colors = colors.permute(0, 3, 1, 2)  # [1, 3, H, W]\n",
    "                metrics[\"psnr\"].append(self.psnr(colors, pixels))\n",
    "                metrics[\"ssim\"].append(self.ssim(colors, pixels))\n",
    "                metrics[\"lpips\"].append(self.lpips(colors, pixels))\n",
    "\n",
    "        if world_rank == 0:\n",
    "            ellipse_time /= len(valloader)\n",
    "\n",
    "            psnr = torch.stack(metrics[\"psnr\"]).mean()\n",
    "            ssim = torch.stack(metrics[\"ssim\"]).mean()\n",
    "            lpips = torch.stack(metrics[\"lpips\"]).mean()\n",
    "            print(\n",
    "                f\"PSNR: {psnr.item():.3f}, SSIM: {ssim.item():.4f}, LPIPS: {lpips.item():.3f} \"\n",
    "                f\"Time: {ellipse_time:.3f}s/image \"\n",
    "                f\"Number of GS: {len(self.splats['means'])}\"\n",
    "            )\n",
    "            # save stats as json\n",
    "            stats = {\n",
    "                \"psnr\": psnr.item(),\n",
    "                \"ssim\": ssim.item(),\n",
    "                \"lpips\": lpips.item(),\n",
    "                \"ellipse_time\": ellipse_time,\n",
    "                \"num_GS\": len(self.splats[\"means\"]),\n",
    "            }\n",
    "            with open(f\"{self.stats_dir}/val_step{step:04d}.json\", \"w\") as f:\n",
    "                json.dump(stats, f)\n",
    "            # save stats to tensorboard\n",
    "            for k, v in stats.items():\n",
    "                self.writer.add_scalar(f\"val/{k}\", v, step)\n",
    "            self.writer.flush()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def render_traj(self, step: int):\n",
    "        \"\"\"Entry for trajectory rendering.\"\"\"\n",
    "        print(\"Running trajectory rendering...\")\n",
    "        cfg = self.cfg\n",
    "        device = self.device\n",
    "\n",
    "        camtoworlds = self.parser.camtoworlds[5:-5]\n",
    "        camtoworlds = generate_interpolated_path(camtoworlds, 1)  # [N, 3, 4]\n",
    "        camtoworlds = np.concatenate(\n",
    "            [\n",
    "                camtoworlds,\n",
    "                np.repeat(np.array([[[0.0, 0.0, 0.0, 1.0]]]), len(camtoworlds), axis=0),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )  # [N, 4, 4]\n",
    "\n",
    "        camtoworlds = torch.from_numpy(camtoworlds).float().to(device)\n",
    "        K = torch.from_numpy(list(self.parser.Ks_dict.values())[0]).float().to(device)\n",
    "        width, height = list(self.parser.imsize_dict.values())[0]\n",
    "\n",
    "        canvas_all = []\n",
    "        for i in tqdm.trange(len(camtoworlds), desc=\"Rendering trajectory\"):\n",
    "            renders, _, _ = self.rasterize_splats(\n",
    "                camtoworlds=camtoworlds[i : i + 1],\n",
    "                Ks=K[None],\n",
    "                width=width,\n",
    "                height=height,\n",
    "                sh_degree=cfg.sh_degree,\n",
    "                near_plane=cfg.near_plane,\n",
    "                far_plane=cfg.far_plane,\n",
    "                render_mode=\"RGB+ED\",\n",
    "            )  # [1, H, W, 4]\n",
    "            colors = torch.clamp(renders[0, ..., 0:3], 0.0, 1.0)  # [H, W, 3]\n",
    "            depths = renders[0, ..., 3:4]  # [H, W, 1]\n",
    "            depths = (depths - depths.min()) / (depths.max() - depths.min())\n",
    "\n",
    "            # write images\n",
    "            canvas = torch.cat(\n",
    "                [colors, depths.repeat(1, 1, 3)], dim=0 if width > height else 1\n",
    "            )\n",
    "            canvas = (canvas.cpu().numpy() * 255).astype(np.uint8)\n",
    "            canvas_all.append(canvas)\n",
    "\n",
    "        # save to video\n",
    "        video_dir = f\"{cfg.result_dir}/videos\"\n",
    "        os.makedirs(video_dir, exist_ok=True)\n",
    "        writer = imageio.get_writer(f\"{video_dir}/traj_{step}.mp4\", fps=30)\n",
    "        for canvas in canvas_all:\n",
    "            writer.append_data(canvas)\n",
    "        writer.close()\n",
    "        print(f\"Video saved to {video_dir}/traj_{step}.mp4\")\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _viewer_render_fn(\n",
    "        self, camera_state: nerfview.CameraState, img_wh: Tuple[int, int]\n",
    "    ):\n",
    "        \"\"\"Callable function for the viewer.\"\"\"\n",
    "        W, H = img_wh\n",
    "        c2w = camera_state.c2w\n",
    "        K = camera_state.get_K(img_wh)\n",
    "        c2w = torch.from_numpy(c2w).float().to(self.device)\n",
    "        K = torch.from_numpy(K).float().to(self.device)\n",
    "\n",
    "        render_colors, _, _ = self.rasterize_splats(\n",
    "            camtoworlds=c2w[None],\n",
    "            Ks=K[None],\n",
    "            width=W,\n",
    "            height=H,\n",
    "            sh_degree=self.cfg.sh_degree,  # active all SH degrees\n",
    "            radius_clip=3.0,  # skip GSs that have small image radius (in pixels)\n",
    "        )  # [1, H, W, 3]\n",
    "        return render_colors[0].cpu().numpy()\n",
    "\n",
    "\n",
    "def main(local_rank: int, world_rank, world_size: int, cfg: Config):\n",
    "    if world_size > 1 and not cfg.disable_viewer:\n",
    "        cfg.disable_viewer = True\n",
    "        if world_rank == 0:\n",
    "            print(\"Viewer is disabled in distributed training.\")\n",
    "\n",
    "    runner = Runner(local_rank, world_rank, world_size, cfg)\n",
    "\n",
    "    if cfg.ckpt is not None:\n",
    "        # run eval only\n",
    "        ckpt = torch.load(cfg.ckpt, map_location=runner.device)\n",
    "        for k in runner.splats.keys():\n",
    "            runner.splats[k].data = ckpt[\"splats\"][k]\n",
    "        runner.eval(step=ckpt[\"step\"])\n",
    "        runner.render_traj(step=ckpt[\"step\"])\n",
    "    else:\n",
    "        runner.train()\n",
    "\n",
    "    if not cfg.disable_viewer:\n",
    "        print(\"Viewer running... Ctrl+C to exit.\")\n",
    "        time.sleep(1000000)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Run",
   "id": "a8f784921ad819b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    Usage:\n",
    "\n",
    "    ```bash\n",
    "    # Single GPU training\n",
    "    CUDA_VISIBLE_DEVICES=0 python simple_trainer.py default\n",
    "\n",
    "    # Distributed training on 4 GPUs: Effectively 4x batch size so run 4x less steps.\n",
    "    CUDA_VISIBLE_DEVICES=0,1,2,3 python simple_trainer.py default --steps_scaler 0.25\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Config objects we can choose between.\n",
    "    # Each is a tuple of (CLI description, config object).\n",
    "    configs = {\n",
    "        \"default\": (\n",
    "            \"Gaussian splatting training using densification heuristics from the original paper.\",\n",
    "            Config(\n",
    "                strategy=DefaultStrategy(verbose=True),\n",
    "            ),\n",
    "        ),\n",
    "        \"mcmc\": (\n",
    "            \"Gaussian splatting training using densification  from the paper '3D Gaussian Splatting as Markov Chain Monte Carlo'.\",\n",
    "            Config(\n",
    "                init_opa=0.5,\n",
    "                init_scale=0.1,\n",
    "                strategy=MCMCStrategy(verbose=True),\n",
    "            ),\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    # We're going to do some advanced tyro stuff to make the CLI nicer.\n",
    "    #\n",
    "    # (1) Build a union type that lets us choose between the two config\n",
    "    # objects.\n",
    "    subcommand_type = tyro.extras.subcommand_type_from_defaults(\n",
    "        defaults={k: v[1] for k, v in configs.items()},\n",
    "        descriptions={k: v[0] for k, v in configs.items()},\n",
    "    )\n",
    "\n",
    "    # (2) Don't let the user override the strategy type provided by the default that they choose.\n",
    "    subcommand_type = tyro.conf.configure(tyro.conf.AvoidSubcommands)(subcommand_type)\n",
    "\n",
    "    cfg = tyro.cli(subcommand_type)\n",
    "    cfg.adjust_steps(cfg.steps_scaler)\n",
    "    cli(main, cfg, verbose=True)"
   ],
   "id": "f0d4c43aad3aeb60"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
